# ğŸ”µ **ğ—•ğ—¶ğ—¼ğ—´ğ—²ğ—»ğ—²ğ˜€ğ˜†ğ˜€ ğ—–ğ—¹ğ—¼ğ˜‚ğ—±Ops ğ˜ƒğŸ¯.ğŸ¬: ğ—”ğ—ªğ—¦ ğ—œğ—»ğ—³ğ—¿ğ—®ğ˜€ğ˜ğ—¿ğ˜‚ğ—°ğ˜ğ˜‚ğ—¿ğ—² & ğ—¦ğ˜ğ—®ğ—¿ ğ—¦ğ—°ğ—µğ—²ğ—ºğ—®**

## **Project Overview**
**Biogenesys v3.0** represents the final leap in the data lifecycle: **Cloud Migration**. In this stage, the project transitions from local CSV processing to a robust **Data Warehouse** environment. We implemented a **Star Schema** architecture on **AWS RDS (PostgreSQL)**, enabling scalable analytics and professional database management.

## **ğŸš€ Key Engineering Features**
* **Cloud Database Implementation:** Deployment of a relational database on **Amazon Web Services (RDS)** using PostgreSQL.
* **Star Schema Architecture:** Transformation of a flat dataset into a structured model with a central **Fact table** and multiple **Dimension tables** for optimized query performance.
* **Automated Cloud Ingestion:** A specialized Python loader that orchestrates the data flow from local outputs to the cloud, utilizing `SQLAlchemy` and `Psycopg2`.
* **Security & Decoupling:** Implementation of a **Modular Configuration Pattern**. Sensitive connection strings (Host, User, Password) are decoupled into a separate `credentials_bio.py` script to prevent exposure and ensure infrastructure integrity.

## **ğŸ“‚ Project Structure**
```text
â”œâ”€â”€ biogenesys_v3.0/
â”‚   â”œâ”€â”€ sql/
â”‚   â”‚   â””â”€â”€ create_star_schema.sql    # DDL for Fact and Dimension tables
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ cloud_loader.py           # The Ingestion Engine
â”‚   â”‚   â””â”€â”€ credentials_template.py   # Secure blueprint for DB access
â”‚   â””â”€â”€ README.md                     # Technical documentation
```

## ğŸ› ï¸ Tech Stack
Cloud Provider: Amazon Web Services (AWS RDS)

Database Engine: PostgreSQL

Language: Python 3.x

Tools: DBeaver (SQL Client), Pandas, SQLAlchemy



## âš™ï¸ How to Run & Deploy

* Prepare AWS RDS: Set up a PostgreSQL instance and ensure your IP is whitelisted in the Security Groups.

* Setup Credentials: Rename credentials_template.py to credentials_bio.py and fill in your AWS Host, User, and Password.

* Deploy Schema: Use DBeaver to execute the scripts located in `/sql/create_star_schema.sql`.


Execute Ingestion in `biogenesys_v3.0/scripts/` :

```text
 Bash
 python cloud_loader.py
```

## ğŸ›¡ï¸ Security Note
The file `credentials_bio.py` is excluded from this repository for security reasons. A `credentials_template.py` is provided as a reference. This approach simulates a real-world enterprise environment where sensitive access keys are never hardcoded into the main source code.

## ğŸ“ˆ Impact
This version transforms the project into a Production-Ready solution. By moving to a Star Schema in the cloud, the data is now structured for high-performance BI reporting. This architecture allows for seamless integration with tools like Power BI, providing faster refresh rates and a single source of truth for decision-making.
